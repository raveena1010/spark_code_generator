Stockcompanies = spark.read.option('header',True).option('delimiter',',').option('inferSchema',True).csv('loc')
StockPrice = spark.read.option('header',True).option('delimiter',',').option('inferSchema',True).csv('loc')
Stockcompanies = Stockcompanies.select(['Sector', 'Security', 'Sub_Industry', 'Ticker_symbol'])
StockPrice = StockPrice.select(['open', 'close', 'date', 'symbol'])
StockPrice = StockPrice.filter('open > 100 and close >100')
StockPrice_alias = StockPrice.toDF(*['cdate', 'csymbol', 'copen', 'cclose'])
Stockcompanies_alias = Stockcompanies.toDF(*['dTicker_symbol', 'dSecurity', 'dSector', 'dSub_Industry'])
StockPrice_Stockcompanies_join = StockPrice_alias.join(Stockcompanies_alias,[StockPrice_alias.csymbol==Stockcompanies_alias.dTicker_symbol,StockPrice_alias.csymbol==Stockcompanies_alias.dSub_Industry],'outer').drop('dTicker_symbol').drop('dSub_Industry')
StockPrice_Stockcompanies_join = StockPrice_Stockcompanies_join.filter('

dSector = "Utilities"')
StockPrice_Stockcompanies_join_alias = StockPrice_Stockcompanies_join.toDF(*['xcdate', 'xcsymbol', 'xcopen', 'xcclose', 'xdSecurity', 'xdSector'])
Stockcompanies_alias = Stockcompanies.toDF(*['yTicker_symbol', 'ySecurity', 'ySector', 'ySub_Industry'])
StockPrice_Stockcompanies_join_Stockcompanies_join = StockPrice_Stockcompanies_join_alias.join(Stockcompanies_alias,[StockPrice_Stockcompanies_join_alias.xcsymbol==Stockcompanies_alias.yTicker_symbol],'inner').drop('yTicker_symbol')
